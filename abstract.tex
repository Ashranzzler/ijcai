  Many biological tasks have been well tackled with data accumulation and machine learning advances, particularly protein-related research. However, RNA structure prediction remains a significant challenge in the field due to RNA data limitations. To offer accurate forecasts of RNA 3D-structure, we propose such a task in defining the distance of arbitrary bases in the RNA primary sequence. This regression task is more informative to subsequent 3D folding methods but more complicated than the well-known RNA secondary structure prediction. 

In this work, we reveal that with only primary sequential information, we can gain accurate inferences on RNA bases' distance with a sizeable pre-trained RNA language model and a well-designed downstream transformer followed by a unrolled constraint layer. Our experiments show that we outperform all convolutional-based models by a preferably big gap while obtaining rather good statistical results. Moreover, we also acquired a comparable performance with other methods at the contact forecast level by degrading our distance prediction output. Moreover, our approach unified the view of language modeling and distance regression, a new perspective by viewing each predicted embedding as a column vector of the decomposed distance matrix. Our framework will foreseeably be a good guidance for 3D-structure prediction.